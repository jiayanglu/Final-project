[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "The dataset, diabetes_binary_health_indicators_BRFSS2015.csv, is a clean dataset of 253,680 survey responses to the CDC’s BRFSS2015. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 other feature variables and is not balanced.\nInformation for all the columns are listed below according to codebook15_llcp (listed in the folder):\n\nDiabetes_binary: 0 = no diabetes; 1 = prediabetes or diabetes\nHighBP: 0 = no high BP; 1 = high BP\nHighChol: 0 = no high cholesterol; 1 = high cholesterol\nCholCheck: 0 = no cholesterol check in 5 years; 1 = yes cholesterol check in 5 years\nBMI: Body Mass Index\nSmoker: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no; 1 = yes\nStroke: (Ever told) you had a stroke. 0 = no; 1 = yes\nHeartDiseaseorAttack: coronary heart disease (CHD) or myocardial infarction (MI). 0 = no; 1 = yes\nPhysActivity: physical activity in past 30 days - not including job. 0 = no; 1 = yes\nFruits: Consume Fruit 1 or more times per day. 0 = no; 1 = yes\nVeggies: Consume Vegetables 1 or more times per day. 0 = no; 1 = yes\nHvyAlcoholConsump: (adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week) 0 = no; 1 = yes\nAnyHealthcare: Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no; 1 = yes\nNoDocbcCost: Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no; 1 = yes\nGenHlth: Would you say that in general your health is: scale 1-5. 1 = excellent; 2 = very good; 3 = good; 4 = fair; 5 = poor\nMentHlth: days of poor mental health. scale 1-30 days\nPhysHlth: physical illness or injury days in past 30 days. scale 1-30\nDiffWalk: Do you have serious difficulty walking or climbing stairs? 0 = no; 1 = yes\nSex: 0 = female; 1 = male\nAge: 13-level age category (_AGEG5YR see codebook) 1 = 18-24; 9 = 60-64; 13 = 80 or older\nEducation: Education level (EDUCA see codebook) scale 1-6. 1 = Never attended school or only kindergarten; 2 = Grades 1 through 8 (Elementary); 3 = Grades 9 through 11 (Some high school); 4 = Grade 12 or GED (High school graduate); 5 = College 1 year to 3 years (Some college or technical school); 6 = College 4 years or more (College graduate)\nIncome: Income scale (INCOME2 see codebook) scale 1-8. 1 = less than $10,000; 2 = Less than $15,000 ($10,000 to less than $15,000); 3 = Less than $20,000 ($15,000 to less than $20,000); 4= Less than $25,000 ($20,000 to less than $25,000); 5 = less than $35,000; 6 = Less than $50,000 ($35,000 to less than $50,000); 7 = Less than $75,000 ($50,000 to less than $75,000); 8 = $75,000 or more\n\nThe purpose of this EDA is to read in data from diabetes_binary_health_indicators_BRFSS2015.csv and to clean BRFSS data into a useable format for modeling based on diabetes disease research regarding factors influencing diabetes disease and other chronic health conditions. Only select features are included in this analysis."
  },
  {
    "objectID": "EDA.html#introduction-section",
    "href": "EDA.html#introduction-section",
    "title": "EDA",
    "section": "",
    "text": "The dataset, diabetes_binary_health_indicators_BRFSS2015.csv, is a clean dataset of 253,680 survey responses to the CDC’s BRFSS2015. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 other feature variables and is not balanced.\nInformation for all the columns are listed below according to codebook15_llcp (listed in the folder):\n\nDiabetes_binary: 0 = no diabetes; 1 = prediabetes or diabetes\nHighBP: 0 = no high BP; 1 = high BP\nHighChol: 0 = no high cholesterol; 1 = high cholesterol\nCholCheck: 0 = no cholesterol check in 5 years; 1 = yes cholesterol check in 5 years\nBMI: Body Mass Index\nSmoker: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no; 1 = yes\nStroke: (Ever told) you had a stroke. 0 = no; 1 = yes\nHeartDiseaseorAttack: coronary heart disease (CHD) or myocardial infarction (MI). 0 = no; 1 = yes\nPhysActivity: physical activity in past 30 days - not including job. 0 = no; 1 = yes\nFruits: Consume Fruit 1 or more times per day. 0 = no; 1 = yes\nVeggies: Consume Vegetables 1 or more times per day. 0 = no; 1 = yes\nHvyAlcoholConsump: (adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week) 0 = no; 1 = yes\nAnyHealthcare: Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no; 1 = yes\nNoDocbcCost: Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no; 1 = yes\nGenHlth: Would you say that in general your health is: scale 1-5. 1 = excellent; 2 = very good; 3 = good; 4 = fair; 5 = poor\nMentHlth: days of poor mental health. scale 1-30 days\nPhysHlth: physical illness or injury days in past 30 days. scale 1-30\nDiffWalk: Do you have serious difficulty walking or climbing stairs? 0 = no; 1 = yes\nSex: 0 = female; 1 = male\nAge: 13-level age category (_AGEG5YR see codebook) 1 = 18-24; 9 = 60-64; 13 = 80 or older\nEducation: Education level (EDUCA see codebook) scale 1-6. 1 = Never attended school or only kindergarten; 2 = Grades 1 through 8 (Elementary); 3 = Grades 9 through 11 (Some high school); 4 = Grade 12 or GED (High school graduate); 5 = College 1 year to 3 years (Some college or technical school); 6 = College 4 years or more (College graduate)\nIncome: Income scale (INCOME2 see codebook) scale 1-8. 1 = less than $10,000; 2 = Less than $15,000 ($10,000 to less than $15,000); 3 = Less than $20,000 ($15,000 to less than $20,000); 4= Less than $25,000 ($20,000 to less than $25,000); 5 = less than $35,000; 6 = Less than $50,000 ($35,000 to less than $50,000); 7 = Less than $75,000 ($50,000 to less than $75,000); 8 = $75,000 or more\n\nThe purpose of this EDA is to read in data from diabetes_binary_health_indicators_BRFSS2015.csv and to clean BRFSS data into a useable format for modeling based on diabetes disease research regarding factors influencing diabetes disease and other chronic health conditions. Only select features are included in this analysis."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "EDA",
    "section": "Data",
    "text": "Data\n\n#load packages needed\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(Metrics)\n\nWarning: package 'Metrics' was built under R version 4.3.3\n\n\n\nAttaching package: 'Metrics'\n\nThe following objects are masked from 'package:caret':\n\n    precision, recall\n\n\n\n#read in csv data\ndata_original &lt;- read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(data_original)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nFrom the output, we have this dataset with 253680 rows and 22 columns.\nNow, we can check sorted unique values in this dataset to learn more about our data\n\nunique_values &lt;- sapply(data_original, unique) \nsorted_unique &lt;- lapply(unique_values, sort)\nsorted_unique\n\n$Diabetes_binary\n[1] 0 1\n\n$HighBP\n[1] 0 1\n\n$HighChol\n[1] 0 1\n\n$CholCheck\n[1] 0 1\n\n$BMI\n [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36\n[26] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61\n[51] 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86\n[76] 87 88 89 90 91 92 95 96 98\n\n$Smoker\n[1] 0 1\n\n$Stroke\n[1] 0 1\n\n$HeartDiseaseorAttack\n[1] 0 1\n\n$PhysActivity\n[1] 0 1\n\n$Fruits\n[1] 0 1\n\n$Veggies\n[1] 0 1\n\n$HvyAlcoholConsump\n[1] 0 1\n\n$AnyHealthcare\n[1] 0 1\n\n$NoDocbcCost\n[1] 0 1\n\n$GenHlth\n[1] 1 2 3 4 5\n\n$MentHlth\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n[26] 25 26 27 28 29 30\n\n$PhysHlth\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n[26] 25 26 27 28 29 30\n\n$DiffWalk\n[1] 0 1\n\n$Sex\n[1] 0 1\n\n$Age\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n$Education\n[1] 1 2 3 4 5 6\n\n$Income\n[1] 1 2 3 4 5 6 7 8\n\n\nMissing values are checked here.\n\n#check total NA data entries from each column\ncolSums(is.na(data_original))\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n#check total zero entried from each column\ncolSums(data_original == 0)\n\n     Diabetes_binary               HighBP             HighChol \n              218334               144851               146089 \n           CholCheck                  BMI               Smoker \n                9470                    0               141257 \n              Stroke HeartDiseaseorAttack         PhysActivity \n              243388               229787                61760 \n              Fruits              Veggies    HvyAlcoholConsump \n               92782                47839               239424 \n       AnyHealthcare          NoDocbcCost              GenHlth \n               12417               232326                    0 \n            MentHlth             PhysHlth             DiffWalk \n              175680               160052               211005 \n                 Sex                  Age            Education \n              141974                    0                    0 \n              Income \n                   0 \n\n\nFirst, from the result, we can see that there are no NA entries from each variable. Second, considering the meaning of different variables, we can see that there are no column with zero values indicating missing values. Altogether, we can conclude that there are no missing values in the whole dataset.\nNext, we can check whether there are duplicated data in this dataset.\n\ndeplicates &lt;- data_original[duplicated(data_original), ]\nnrow(deplicates)\n\n[1] 24206\n\n#from the output, we see that there are 24206 duplicates\n\n#then we need to exclude data that are duplicated\n#dataset data is updated here\ndata_no_duplicates &lt;- data_original[!duplicated(data_original), ]\nnrow(data_no_duplicates)\n\n[1] 229474\n\n#from the output, there are total 229,474 rows in the updated dataset data\n\nNow we want to convert numeric variables to factors according to previous sorted unique values for each variable.\n\ndata &lt;- data_no_duplicates\n\ndata$Diabetes_binary &lt;- factor(\n  data$Diabetes_binary, \n  levels = c(0,1), \n  labels = c(\"No_diabetes\", \"Prediabetes_or_diabetes\")\n)\n\ndata$HighBP &lt;- factor(\n  data$HighBP,\n  levels = c(0,1), \n  labels = c(\"No_high_BP\", \"High_BP\")\n)\n\ndata$HighChol &lt;- factor(\n  data$HighChol,\n  levels = c(0,1), \n  labels = c(\"No_high_cholesterol\", \"High_cholesterol\")\n)\n\ndata$CholCheck &lt;- factor(\n  data$CholCheck,\n  levels = c(0,1), \n  labels = c(\"No_cholesterol_check\", \"Cholesterol_check\")\n)\n\ndata$Smoker &lt;- factor(\n  data$Smoker,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Stroke &lt;- factor(\n  data$Stroke,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HeartDiseaseorAttack &lt;- factor(\n  data$HeartDiseaseorAttack,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$PhysActivity &lt;- factor(\n  data$PhysActivity,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Fruits &lt;- factor(\n  data$Fruits,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Veggies &lt;- factor(\n  data$Veggies,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HvyAlcoholConsump &lt;- factor(\n  data$HvyAlcoholConsump,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$AnyHealthcare &lt;- factor(\n  data$AnyHealthcare,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$NoDocbcCost &lt;- factor(\n  data$NoDocbcCost,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$GenHlth &lt;- factor(\n  data$GenHlth,\n  levels = c(1, 2, 3, 4, 5), \n  labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n)\n\ndata$DiffWalk &lt;- factor(\n  data$DiffWalk,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Sex &lt;- factor(\n  data$Sex,\n  levels = c(0,1), \n  labels = c(\"Female\", \"Male\")\n)\n\ndata$Age &lt;- factor(\n  data$Age,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), \n  labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80_or_older\")\n)\n\ndata$Education &lt;- factor(\n  data$Education,\n  levels = c(1, 2, 3, 4, 5, 6), \n  labels = c(\"Never_attended_school_or_only_kindergarten\", \"Elementary\", \"Some_high_school\", \"High school_graduate\", \"Some_college_or_technical_school\", \"College_graduate\")\n)\n\ndata$Income &lt;- factor(\n  data$Income,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8), \n  labels = c(\"Less_than_10K\", \"10K_to_less_than_15K\", \"15K_to_Less_than_20K\", \"20K_to_less_than_25K\", \"25K_to_less_than_35K\", \"35K_to_less_than_50k\", \"50k_to_less_than_75k\", \"75k_or_more\")\n)\n\nstr(data)\n\ntibble [229,474 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"No_diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"No_high_BP\",\"High_BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No_high_cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"No_cholesterol_check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num [1:229474] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:229474] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:229474] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never_attended_school_or_only_kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"Less_than_10K\",..: 3 1 8 6 4 8 7 4 1 3 ..."
  },
  {
    "objectID": "EDA.html#summarizations",
    "href": "EDA.html#summarizations",
    "title": "EDA",
    "section": "Summarizations",
    "text": "Summarizations\nLet’s look at a summary of each numeric column in data, including minimum, 1st quartile (Q1), median (Q2), mean, 3rd quartile (Q3), and maximum values.\n\nsummary(data_no_duplicates)\n\n Diabetes_binary      HighBP          HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :1.0000  \n Mean   :0.1529   Mean   :0.4543   Mean   :0.4416   Mean   :0.9595  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000      \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000      \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.0000      \n Mean   :28.69   Mean   :0.4658   Mean   :0.04482   Mean   :0.1033      \n 3rd Qu.:32.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.0000      \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000      \n  PhysActivity       Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.00000  \n Median :1.000   Median :1.0000   Median :1.0000   Median :0.00000  \n Mean   :0.733   Mean   :0.6127   Mean   :0.7946   Mean   :0.06079  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.00000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n AnyHealthcare    NoDocbcCost         GenHlth         MentHlth    \n Min.   :0.000   Min.   :0.00000   Min.   :1.000   Min.   : 0.00  \n 1st Qu.:1.000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.00  \n Median :1.000   Median :0.00000   Median :3.000   Median : 0.00  \n Mean   :0.946   Mean   :0.09292   Mean   :2.602   Mean   : 3.51  \n 3rd Qu.:1.000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.00  \n Max.   :1.000   Max.   :1.00000   Max.   :5.000   Max.   :30.00  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.681   Mean   :0.1858   Mean   :0.4391   Mean   : 8.085  \n 3rd Qu.: 4.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:4.000  \n Median :5.00   Median :6.000  \n Mean   :4.98   Mean   :5.889  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nLet’s also view our response variable Diabetes_binary.\n\np &lt;- ggplot(data = data, aes(x = Diabetes_binary)) +\n  geom_bar() +\n  labs(x = \"Diabetes Status\") + \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\nprint(p)\n\n\n\n\n\n\n\n\nNow let’s look at the distributions of variables and their relation with Diabetes_binary in bar charts.\n\n# Loop through each variable except the first variable Diabetes_binary\nfor (i in 2:ncol(data)) {\n  variable &lt;- data[[i]]\n  \n  p &lt;- ggplot(data = data, aes(x = variable, fill = Diabetes_binary)) +\n    geom_bar() +\n    labs(x = names(data)[i]) +  \n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s further look at correlation heatmap which shows relation between variables.\n\n# Compute correlation matrix\ncorr_matrix &lt;- cor(data_no_duplicates)\n\n# Convert correlation matrix to data frame for easier manipulation\ncorr_df &lt;- as.data.frame(as.table(corr_matrix))\n\ncorr &lt;- corr_df |&gt;\n  filter(Var2 == \"Diabetes_binary\") |&gt;\n  arrange(desc(Freq))\ncorr\n\n                   Var1            Var2        Freq\n1       Diabetes_binary Diabetes_binary  1.00000000\n2               GenHlth Diabetes_binary  0.27693982\n3                HighBP Diabetes_binary  0.25431802\n4              DiffWalk Diabetes_binary  0.20530219\n5                   BMI Diabetes_binary  0.20508596\n6              HighChol Diabetes_binary  0.19494411\n7                   Age Diabetes_binary  0.17726335\n8  HeartDiseaseorAttack Diabetes_binary  0.16821317\n9              PhysHlth Diabetes_binary  0.15621083\n10               Stroke Diabetes_binary  0.09919330\n11            CholCheck Diabetes_binary  0.07252338\n12             MentHlth Diabetes_binary  0.05415268\n13               Smoker Diabetes_binary  0.04550399\n14                  Sex Diabetes_binary  0.03272416\n15        AnyHealthcare Diabetes_binary  0.02533134\n16          NoDocbcCost Diabetes_binary  0.02004828\n17               Fruits Diabetes_binary -0.02480534\n18              Veggies Diabetes_binary -0.04173376\n19    HvyAlcoholConsump Diabetes_binary -0.06595002\n20         PhysActivity Diabetes_binary -0.10040433\n21            Education Diabetes_binary -0.10268615\n22               Income Diabetes_binary -0.14065874\n\n# Rename columns for clarity\ncolnames(corr_df) &lt;- c(\"Variable1\", \"Variable2\", \"Correlation\")\n\n# Sort correlation values from largest to smallest\nsorted_corr_df &lt;- corr_df[order(-abs(corr_df$Correlation)), ]\n\n# Create correlation heatmap\ncorrplot::corrplot(corr_matrix, \n                   method = \"color\", \n                   type = \"lower\", \n                   order = \"hclust\",\n                   tl.col = \"black\",\n                   tl.srt = 45)\n\n\n\n\n\n\n\n\nFrom all the exploratory analysis above, we can see that there are variableshighly positively correlated with each other: PhysHlth and GenHlth, PhysHlth and DiffWalk, GenHlth and DiffWalk, Income and Education. There are variables highly negativelycorrelated with each other: Income and GenHlth, Income and DiffWalk. Variables (GenHlth, HighBP, DiffWalk, BMI, HighChol, Age, HeartDiseaseorAttack, PhysHlth) are positively correlated (Freq over 0.1) with Diabetes_binary; variables (Income, Education, PhysActivity) are negatively correlated (Freq lower than -0.1) with Diabetes_binary."
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\nWe do not need to use preprocessed data for tree modeling. Therefore, I use train data without preprocessing here.\nNow, we can fit a classification tree with a grid of values for the complexity parameter (cp). cp is a tuning parameter used in CART (Classification and Regression Trees) to control the complexity of the decision tree model. It represents the cost of adding another predictor split to the tree. A larger cp value results in a simpler tree (fewer splits), while a smaller cp value allows the tree to be more complex (more splits).\n\nset.seed(11)\n\nclassification_fit &lt;- train(Diabetes_binary ~ .,\n                            data = train_data,\n                            method = \"rpart\",\n                            metric = \"logLoss\",\n                            trControl = trainControl(method = \"cv\", \n                                                     number = 5,\n                                                     classProbs = TRUE,\n                                                     summaryFunction = mnLogLoss),\n                            tuneGrid = expand.grid(cp = seq(0, 0.1, by = 0.001)))\nclassification_fit\n\nCART \n\n160632 samples\n    21 predictor\n     2 classes: 'No_diabetes', 'Prediabetes_or_diabetes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 128507, 128505, 128505, 128505, 128506 \nResampling results across tuning parameters:\n\n  cp     logLoss  \n  0.000  0.4696247\n  0.001  0.3821432\n  0.002  0.3829163\n  0.003  0.3829226\n  0.004  0.4277851\n  0.005  0.4277851\n  0.006  0.4277851\n  0.007  0.4277851\n  0.008  0.4277851\n  0.009  0.4277851\n  0.010  0.4277851\n  0.011  0.4277851\n  0.012  0.4277851\n  0.013  0.4277851\n  0.014  0.4277851\n  0.015  0.4277851\n  0.016  0.4277851\n  0.017  0.4277851\n  0.018  0.4277851\n  0.019  0.4277851\n  0.020  0.4277851\n  0.021  0.4277851\n  0.022  0.4277851\n  0.023  0.4277851\n  0.024  0.4277851\n  0.025  0.4277851\n  0.026  0.4277851\n  0.027  0.4277851\n  0.028  0.4277851\n  0.029  0.4277851\n  0.030  0.4277851\n  0.031  0.4277851\n  0.032  0.4277851\n  0.033  0.4277851\n  0.034  0.4277851\n  0.035  0.4277851\n  0.036  0.4277851\n  0.037  0.4277851\n  0.038  0.4277851\n  0.039  0.4277851\n  0.040  0.4277851\n  0.041  0.4277851\n  0.042  0.4277851\n  0.043  0.4277851\n  0.044  0.4277851\n  0.045  0.4277851\n  0.046  0.4277851\n  0.047  0.4277851\n  0.048  0.4277851\n  0.049  0.4277851\n  0.050  0.4277851\n  0.051  0.4277851\n  0.052  0.4277851\n  0.053  0.4277851\n  0.054  0.4277851\n  0.055  0.4277851\n  0.056  0.4277851\n  0.057  0.4277851\n  0.058  0.4277851\n  0.059  0.4277851\n  0.060  0.4277851\n  0.061  0.4277851\n  0.062  0.4277851\n  0.063  0.4277851\n  0.064  0.4277851\n  0.065  0.4277851\n  0.066  0.4277851\n  0.067  0.4277851\n  0.068  0.4277851\n  0.069  0.4277851\n  0.070  0.4277851\n  0.071  0.4277851\n  0.072  0.4277851\n  0.073  0.4277851\n  0.074  0.4277851\n  0.075  0.4277851\n  0.076  0.4277851\n  0.077  0.4277851\n  0.078  0.4277851\n  0.079  0.4277851\n  0.080  0.4277851\n  0.081  0.4277851\n  0.082  0.4277851\n  0.083  0.4277851\n  0.084  0.4277851\n  0.085  0.4277851\n  0.086  0.4277851\n  0.087  0.4277851\n  0.088  0.4277851\n  0.089  0.4277851\n  0.090  0.4277851\n  0.091  0.4277851\n  0.092  0.4277851\n  0.093  0.4277851\n  0.094  0.4277851\n  0.095  0.4277851\n  0.096  0.4277851\n  0.097  0.4277851\n  0.098  0.4277851\n  0.099  0.4277851\n  0.100  0.4277851\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.001.\n\n\nFrom the output, we can see that the cp value that minimizes the chosen metric (logLoss) on the training set is 0.001. This cp value represents the optimal balance between model complexity and performance. The logLoss value at cp = 0.001 is 0.3821432."
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "Random Forest",
    "text": "Random Forest\n\nset.seed(11)\n\nrf_fit &lt;- train(Diabetes_binary ~ .,\n                data = train_data,\n                method = \"ranger\",\n                metric = \"logLoss\",\n                num.trees = 100,\n                trControl = trainControl(method = \"cv\", \n                                         number = 3,\n                                         classProbs = TRUE,\n                                         summaryFunction = mnLogLoss),\n                tuneGrid = expand.grid(mtry = 1:sqrt(ncol(train_data)-1),\n                                       splitrule = \"extratrees\",\n                                       min.node.size = 100))\nrf_fit\n\nRandom Forest \n\n160632 samples\n    21 predictor\n     2 classes: 'No_diabetes', 'Prediabetes_or_diabetes' \n\nNo pre-processing\nResampling: Cross-Validated (3 fold) \nSummary of sample sizes: 107089, 107088, 107087 \nResampling results across tuning parameters:\n\n  mtry  logLoss  \n  1     0.3881142\n  2     0.3613238\n  3     0.3527377\n  4     0.3492082\n\nTuning parameter 'splitrule' was held constant at a value of extratrees\n\nTuning parameter 'min.node.size' was held constant at a value of 100\nlogLoss was used to select the optimal model using the smallest value.\nThe final values used for the model were mtry = 4, splitrule = extratrees\n and min.node.size = 100.\n\n\nFrom the output, we can see that the best tuning parameters to minimizes the chosen metric (logLoss) on the training set are mtry=4, splitrule = extratrees, and min.node.size = 100. The logLoss value at mtry=4, splitrule = extratrees, and min.node.size = 100 is 0.3492082."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\n\n#use logLoss as our metric for classification model:\n#get predicted values corresponding to the probabilities that each observation in test data belongs to \"Prediabetes_or_diabetes\"\npredicted_prob_classification &lt;- predict(classification_fit,\n                                         newdata = select(test_data, -Diabetes_binary),\n                                         type='prob')\n#convert variable Diabetes_binary from factor to numeric in order to use logLoss function\nlog_loss_classification &lt;- logLoss(as.numeric(as.character(test_data$Diabetes_binary) == \"Prediabetes_or_diabetes\"),\n                                   predicted_prob_classification$Prediabetes_or_diabetes)\n\n#use logLoss as our metric for classification model:\npredicted_prob_rf &lt;- predict(rf_fit,\n                             newdata = select(test_data, -Diabetes_binary),\n                             type='prob')\n#convert variable Diabetes_binary from factor to numeric in order to use logLoss function\nlog_loss_rf &lt;- logLoss(as.numeric(as.character(test_data$Diabetes_binary) == \"Prediabetes_or_diabetes\"),\n                                   predicted_prob_rf$Prediabetes_or_diabetes)\n\n#list of log-loss values obtained from each model\nlist(log_loss_logistic_M3 = log_loss_logistic_M3,\n     log_loss_classification = log_loss_classification,\n     log_loss_rf = log_loss_rf)\n\n$log_loss_logistic_M3\n[1] 0.3497698\n\n$log_loss_classification\n[1] 0.3828286\n\n$log_loss_rf\n[1] 0.3518978\n\n\nFrom the result, we can see that our logistic_M3 has the lowest log-loss value (0.3497698) among all the models, which means that the logistic_M3’s predicted probabilities are closest to the actual observed outcomes among all models. Therefore, the logistic_M3 model overall did the best job (in terms of log-loss metric) on the test set."
  },
  {
    "objectID": "EDA.html#split-data",
    "href": "EDA.html#split-data",
    "title": "EDA",
    "section": "Split Data",
    "text": "Split Data\nSplit this data into a training and test set. Before modeling, let’s scale and centralized data.\n\nset.seed(11)\n\n\ntrainIndex &lt;- createDataPartition(data$Diabetes_binary, p = .7,\n                                  list = FALSE,\n                                  times = 1)\n\ntrain_data &lt;-  data[trainIndex, ]\ntest_data &lt;- data[-trainIndex, ]\n\n#check the dimensions of our training data and testing data frame\ndim(train_data)\n\n[1] 160632     22\n\ndim(test_data)\n\n[1] 68842    22\n\npre_proc_values &lt;- preProcess(train_data, method = c(\"center\", \"scale\"))\n\n#Scaling and centralizing train and test data sets.\ntrain_transformed &lt;- predict(pre_proc_values, train_data)\ntest_transformed &lt;- predict(pre_proc_values, test_data)"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "#load packages needed\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(Metrics)\n\nWarning: package 'Metrics' was built under R version 4.3.3\n\n\n\nAttaching package: 'Metrics'\n\nThe following objects are masked from 'package:caret':\n\n    precision, recall\n\nlibrary(rpart)\n\nWarning: package 'rpart' was built under R version 4.3.3\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.3.3\n\n\n\n#read in csv data\ndata_original &lt;- read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(data_original)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nNext, we can check whether there are duplicated data in this dataset.\n\ndeplicates &lt;- data_original[duplicated(data_original), ]\nnrow(deplicates)\n\n[1] 24206\n\n#from the output, we see that there are 24206 duplicates\n\n#then we need to exclude data that are duplicated\n#dataset data is updated here\ndata_no_duplicates &lt;- data_original[!duplicated(data_original), ]\nnrow(data_no_duplicates)\n\n[1] 229474\n\n#from the output, there are total 229,474 rows in the updated dataset data\n\nNow we want to convert numeric variables to factors according to previous sorted unique values for each variable.\n\ndata &lt;- data_no_duplicates\n\ndata$Diabetes_binary &lt;- factor(\n  data$Diabetes_binary, \n  levels = c(0,1), \n  labels = c(\"No_diabetes\", \"Prediabetes_or_diabetes\")\n)\n\ndata$HighBP &lt;- factor(\n  data$HighBP,\n  levels = c(0,1), \n  labels = c(\"No_high_BP\", \"High_BP\")\n)\n\ndata$HighChol &lt;- factor(\n  data$HighChol,\n  levels = c(0,1), \n  labels = c(\"No_high_cholesterol\", \"High_cholesterol\")\n)\n\ndata$CholCheck &lt;- factor(\n  data$CholCheck,\n  levels = c(0,1), \n  labels = c(\"No_cholesterol_check\", \"Cholesterol_check\")\n)\n\ndata$Smoker &lt;- factor(\n  data$Smoker,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Stroke &lt;- factor(\n  data$Stroke,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HeartDiseaseorAttack &lt;- factor(\n  data$HeartDiseaseorAttack,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$PhysActivity &lt;- factor(\n  data$PhysActivity,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Fruits &lt;- factor(\n  data$Fruits,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Veggies &lt;- factor(\n  data$Veggies,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HvyAlcoholConsump &lt;- factor(\n  data$HvyAlcoholConsump,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$AnyHealthcare &lt;- factor(\n  data$AnyHealthcare,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$NoDocbcCost &lt;- factor(\n  data$NoDocbcCost,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$GenHlth &lt;- factor(\n  data$GenHlth,\n  levels = c(1, 2, 3, 4, 5), \n  labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n)\n\ndata$DiffWalk &lt;- factor(\n  data$DiffWalk,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Sex &lt;- factor(\n  data$Sex,\n  levels = c(0,1), \n  labels = c(\"Female\", \"Male\")\n)\n\ndata$Age &lt;- factor(\n  data$Age,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), \n  labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80_or_older\")\n)\n\ndata$Education &lt;- factor(\n  data$Education,\n  levels = c(1, 2, 3, 4, 5, 6), \n  labels = c(\"Never_attended_school_or_only_kindergarten\", \"Elementary\", \"Some_high_school\", \"High school_graduate\", \"Some_college_or_technical_school\", \"College_graduate\")\n)\n\ndata$Income &lt;- factor(\n  data$Income,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8), \n  labels = c(\"Less_than_10K\", \"10K_to_less_than_15K\", \"15K_to_Less_than_20K\", \"20K_to_less_than_25K\", \"25K_to_less_than_35K\", \"35K_to_less_than_50k\", \"50k_to_less_than_75k\", \"75k_or_more\")\n)\n\nstr(data)\n\ntibble [229,474 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"No_diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"No_high_BP\",\"High_BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No_high_cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"No_cholesterol_check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num [1:229474] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:229474] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:229474] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never_attended_school_or_only_kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"Less_than_10K\",..: 3 1 8 6 4 8 7 4 1 3 ..."
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "#load packages needed\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(Metrics)\n\nWarning: package 'Metrics' was built under R version 4.3.3\n\n\n\nAttaching package: 'Metrics'\n\nThe following objects are masked from 'package:caret':\n\n    precision, recall\n\nlibrary(rpart)\n\nWarning: package 'rpart' was built under R version 4.3.3\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.3.3\n\n\n\n#read in csv data\ndata_original &lt;- read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(data_original)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nNext, we can check whether there are duplicated data in this dataset.\n\ndeplicates &lt;- data_original[duplicated(data_original), ]\nnrow(deplicates)\n\n[1] 24206\n\n#from the output, we see that there are 24206 duplicates\n\n#then we need to exclude data that are duplicated\n#dataset data is updated here\ndata_no_duplicates &lt;- data_original[!duplicated(data_original), ]\nnrow(data_no_duplicates)\n\n[1] 229474\n\n#from the output, there are total 229,474 rows in the updated dataset data\n\nNow we want to convert numeric variables to factors according to previous sorted unique values for each variable.\n\ndata &lt;- data_no_duplicates\n\ndata$Diabetes_binary &lt;- factor(\n  data$Diabetes_binary, \n  levels = c(0,1), \n  labels = c(\"No_diabetes\", \"Prediabetes_or_diabetes\")\n)\n\ndata$HighBP &lt;- factor(\n  data$HighBP,\n  levels = c(0,1), \n  labels = c(\"No_high_BP\", \"High_BP\")\n)\n\ndata$HighChol &lt;- factor(\n  data$HighChol,\n  levels = c(0,1), \n  labels = c(\"No_high_cholesterol\", \"High_cholesterol\")\n)\n\ndata$CholCheck &lt;- factor(\n  data$CholCheck,\n  levels = c(0,1), \n  labels = c(\"No_cholesterol_check\", \"Cholesterol_check\")\n)\n\ndata$Smoker &lt;- factor(\n  data$Smoker,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Stroke &lt;- factor(\n  data$Stroke,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HeartDiseaseorAttack &lt;- factor(\n  data$HeartDiseaseorAttack,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$PhysActivity &lt;- factor(\n  data$PhysActivity,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Fruits &lt;- factor(\n  data$Fruits,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Veggies &lt;- factor(\n  data$Veggies,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$HvyAlcoholConsump &lt;- factor(\n  data$HvyAlcoholConsump,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$AnyHealthcare &lt;- factor(\n  data$AnyHealthcare,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$NoDocbcCost &lt;- factor(\n  data$NoDocbcCost,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$GenHlth &lt;- factor(\n  data$GenHlth,\n  levels = c(1, 2, 3, 4, 5), \n  labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n)\n\ndata$DiffWalk &lt;- factor(\n  data$DiffWalk,\n  levels = c(0,1), \n  labels = c(\"No\", \"Yes\")\n)\n\ndata$Sex &lt;- factor(\n  data$Sex,\n  levels = c(0,1), \n  labels = c(\"Female\", \"Male\")\n)\n\ndata$Age &lt;- factor(\n  data$Age,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), \n  labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80_or_older\")\n)\n\ndata$Education &lt;- factor(\n  data$Education,\n  levels = c(1, 2, 3, 4, 5, 6), \n  labels = c(\"Never_attended_school_or_only_kindergarten\", \"Elementary\", \"Some_high_school\", \"High school_graduate\", \"Some_college_or_technical_school\", \"College_graduate\")\n)\n\ndata$Income &lt;- factor(\n  data$Income,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8), \n  labels = c(\"Less_than_10K\", \"10K_to_less_than_15K\", \"15K_to_Less_than_20K\", \"20K_to_less_than_25K\", \"25K_to_less_than_35K\", \"35K_to_less_than_50k\", \"50k_to_less_than_75k\", \"75k_or_more\")\n)\n\nstr(data)\n\ntibble [229,474 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"No_diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"No_high_BP\",\"High_BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No_high_cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"No_cholesterol_check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num [1:229474] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:229474] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:229474] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never_attended_school_or_only_kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"Less_than_10K\",..: 3 1 8 6 4 8 7 4 1 3 ..."
  },
  {
    "objectID": "Modeling.html#split-data",
    "href": "Modeling.html#split-data",
    "title": "Modeling",
    "section": "Split Data",
    "text": "Split Data\nSplit this data into a training and test set. Before modeling, let’s scale and centralized data.\n\nset.seed(11)\n\ntrainIndex &lt;- createDataPartition(data$Diabetes_binary, p = .7,\n                                  list = FALSE,\n                                  times = 1)\n\ntrain_data &lt;-  data[trainIndex, ]\ntest_data &lt;- data[-trainIndex, ]\n\n#check the dimensions of our training data and testing data frame\ndim(train_data)\n\n[1] 160632     22\n\ndim(test_data)\n\n[1] 68842    22\n\npre_proc_values &lt;- preProcess(train_data, method = c(\"center\", \"scale\"))\n\n#Scaling and centralizing train and test data sets.\ntrain_transformed &lt;- predict(pre_proc_values, train_data)\ntest_transformed &lt;- predict(pre_proc_values, test_data)"
  },
  {
    "objectID": "Modeling.html#logistic-regression-models",
    "href": "Modeling.html#logistic-regression-models",
    "title": "Modeling",
    "section": "Logistic Regression Models",
    "text": "Logistic Regression Models\nI use preprocessed data (train_transformed) as my train data here in logistic regression models.\n\nLogistic regression Model 1\n\nset.seed(11)\n\ntrctrl &lt;- trainControl(method = \"cv\", number = 5)\n\nlogistic_M1_fit &lt;- train(Diabetes_binary ~ ., \n                         data = train_transformed, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         trControl=trctrl)\n\n\n\nLogistic regression Model 2\n\nset.seed(11)\n\nlogistic_M2_fit &lt;- train(Diabetes_binary ~ . - NoDocbcCost - Fruits - AnyHealthcare + PhysHlth:GenHlth + PhysHlth:DiffWalk + GenHlth:DiffWalk + Income:Education + Income:GenHlth + Income:DiffWalk,\n                         data = train_transformed, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         trControl=trctrl)\n\n\n\nLogistic regression Model 3\n\nset.seed(11)\n\nlogistic_M3_fit &lt;- train(Diabetes_binary ~ GenHlth + HighBP + DiffWalk + BMI + HighChol + Age + HeartDiseaseorAttack + PhysHlth + Income + PhysActivity, \n                         data = train_transformed, \n                         method = \"glm\",\n                         family=\"binomial\",\n                         trControl=trctrl)\n\n\n\nModels comparison\nObtain log-loss value for each model:\n\n#use logLoss as our metric for logistic M1 model:\n#get predicted values corresponding to the probabilities that each observation in test data belongs to \"Prediabetes_or_diabetes\"\npredicted_prob_M1 &lt;- predict(logistic_M1_fit,\n                             newdata = select(test_transformed, -Diabetes_binary), type='prob')\n\n#convert variable Diabetes_binary from factor to numeric in order to use logLoss function\nlog_loss_logistic_M1 &lt;- logLoss(as.numeric(as.character(test_transformed$Diabetes_binary) == \"Prediabetes_or_diabetes\"),\n                                predicted_prob_M1$Prediabetes_or_diabetes)\n\n#use logLoss  as our metric for logistic M2 model:\n\npredicted_prob_M2 &lt;- predict(logistic_M2_fit,\n                             newdata = select(test_transformed, -Diabetes_binary), type='prob')\n\nlog_loss_logistic_M2 &lt;- logLoss(as.numeric(as.character(test_transformed$Diabetes_binary) == \"Prediabetes_or_diabetes\"),\n                                predicted_prob_M2$Prediabetes_or_diabetes)\n\n#use logLoss as our metric for logistic M3 model:\n\npredicted_prob_M3 &lt;- predict(logistic_M3_fit,\n                             newdata = select(test_transformed, -Diabetes_binary), type='prob')\n\nlog_loss_logistic_M3 &lt;- logLoss(as.numeric(as.character(test_transformed$Diabetes_binary) == \"Prediabetes_or_diabetes\"),\n                                predicted_prob_M3$Prediabetes_or_diabetes)\n\n#list of log-loss values obtained from each logistic model\nlist(log_loss_logistic_M1 = log_loss_logistic_M1, log_loss_logistic_M2 = log_loss_logistic_M2, log_loss_logistic_M3 = log_loss_logistic_M3)\n\n$log_loss_logistic_M1\n[1] 0.3466268\n\n$log_loss_logistic_M2\n[1] 0.3462027\n\n$log_loss_logistic_M3\n[1] 0.3497698\n\n\nFrom the result after using logLoss(), we can see that all 3 logistic models have similar log-loss values (between 0.34 to 0.35) when using training data. Therefore, considering the complexity of models, logistic_M3_fit could be chosen as the best model among these three models since it is the simplest model among them."
  }
]